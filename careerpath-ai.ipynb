{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U google-generativeai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T18:26:16.789135Z","iopub.execute_input":"2025-11-20T18:26:16.789501Z","iopub.status.idle":"2025-11-20T18:26:20.877157Z","shell.execute_reply.started":"2025-11-20T18:26:16.789474Z","shell.execute_reply":"2025-11-20T18:26:20.875959Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import google.generativeai as genai\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T18:26:20.878994Z","iopub.execute_input":"2025-11-20T18:26:20.879852Z","iopub.status.idle":"2025-11-20T18:26:20.884511Z","shell.execute_reply.started":"2025-11-20T18:26:20.879820Z","shell.execute_reply":"2025-11-20T18:26:20.883392Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nimport google.generativeai as genai\nimport os\n\nuser_secrets = UserSecretsClient()\nmy_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n\nos.environ[\"GOOGLE_API_KEY\"] = my_key\ngenai.configure(api_key=my_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T18:28:04.459902Z","iopub.execute_input":"2025-11-20T18:28:04.460254Z","iopub.status.idle":"2025-11-20T18:28:04.697491Z","shell.execute_reply.started":"2025-11-20T18:28:04.460228Z","shell.execute_reply":"2025-11-20T18:28:04.696233Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from dataclasses import dataclass, field\nfrom typing import List, Dict\nfrom datetime import datetime\n@dataclass\nclass Memory:\n    messages: List[Dict] = field(default_factory=list)\n    max_history: int = 20\n\n    def add(self, role, content):\n        self.messages.append({\n            \"role\": role,\n            \"content\": content,\n            \"time\": datetime.now().isoformat()\n        })\n        # Keep memory within the limit\n        if len(self.messages) > self.max_history:\n            self.messages = self.messages[-self.max_history:]\n\n    def get_context(self):\n        # Formats the conversation history for the LLM\n        out = \"\"\n        for m in self.messages:\n            out += f\"{m['role']}: {m['content']}\\n\"\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T18:28:04.698704Z","iopub.execute_input":"2025-11-20T18:28:04.699059Z","iopub.status.idle":"2025-11-20T18:28:04.706016Z","shell.execute_reply.started":"2025-11-20T18:28:04.699039Z","shell.execute_reply":"2025-11-20T18:28:04.704990Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"class IntentAgent:\n    def classify(self, message):\n        text = message.lower()\n        \n        # 1. Resume / CV Parsing\n        if any(word in text for word in [\"resume\", \"cv\", \"bio\", \"review\"]):\n            return \"resume_review\", \"high\"\n        \n        # 2. Learning Paths / Roadmaps\n        if any(word in text for word in [\"roadmap\", \"learn\", \"study\", \"course\", \"path\"]):\n            return \"learning_path\", \"medium\"\n        \n        # 3. Interview Preparation\n        if any(word in text for word in [\"interview\", \"mock\", \"questions\", \"behavioral\"]):\n            return \"interview_prep\", \"high\"\n            \n        # 4. General\n        if \"help\" in text:\n            return \"general_help\", \"low\"\n            \n        return \"general\", \"low\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T18:28:04.706965Z","iopub.execute_input":"2025-11-20T18:28:04.707237Z","iopub.status.idle":"2025-11-20T18:28:04.726843Z","shell.execute_reply.started":"2025-11-20T18:28:04.707217Z","shell.execute_reply":"2025-11-20T18:28:04.725989Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Reply Agent ---\nimport google.generativeai as genai\n\nclass ReplyAgent:\n    def __init__(self):\n        self.model = genai.GenerativeModel('gemini-2.0-flash')\n\n    def create_reply(self, message, intent, urgency, history_context):\n        prompt = f\"\"\"\n        You are a helpful Career Path AI Coach.\n        \n        CONVERSATION HISTORY:\n        {history_context}\n        \n        CURRENT USER INPUT: \"{message}\"\n        DETECTED INTENT: {intent} (Urgency: {urgency})\n        \n        INSTRUCTIONS:\n        - If the intent is 'resume_review', provide constructive feedback or ask for the resume text.\n        - If 'learning_path', suggest a brief, step-by-step roadmap (max 3 steps) for the topic.\n        - If 'interview_prep', offer a mock question or a tip.\n        - Be concise, encouraging, and professional.\n        \"\"\"\n        \n        try:\n            response = self.model.generate_content(prompt)\n            return response.text\n        except Exception as e:\n            return f\"AI Error: {str(e)}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T18:28:04.728618Z","iopub.execute_input":"2025-11-20T18:28:04.728854Z","iopub.status.idle":"2025-11-20T18:28:04.745097Z","shell.execute_reply.started":"2025-11-20T18:28:04.728836Z","shell.execute_reply":"2025-11-20T18:28:04.744279Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"class Coordinator:\n    def __init__(self):\n        self.intent_agent = IntentAgent()\n        self.reply_agent = ReplyAgent()\n        self.memory = Memory()\n\n    def ask(self, message):\n        # 1. Store User Message in Memory\n        self.memory.add(\"user\", message)\n        \n        # 2. Determine Intent (Agent 1)\n        intent, urgency = self.intent_agent.classify(message)\n        \n        # 3. Retrieve Context from Memory\n        context_str = self.memory.get_context()\n        \n        # 4. Generate Reply using LLM (Agent 2)\n        # We pass 'context_str' here, which fixes the previous error\n        reply = self.reply_agent.create_reply(message, intent, urgency, context_str)\n\n        # 5. Store Agent Reply in Memory\n        self.memory.add(\"agent\", reply)\n        \n        return {\n            \"intent\": intent,\n            \"reply\": reply\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T18:28:04.745986Z","iopub.execute_input":"2025-11-20T18:28:04.746235Z","iopub.status.idle":"2025-11-20T18:28:04.766754Z","shell.execute_reply.started":"2025-11-20T18:28:04.746215Z","shell.execute_reply":"2025-11-20T18:28:04.765851Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Initialize the Career Agent\ncareer_bot = Coordinator()\n\n# Test Messages\nmessages = [\n    \"I need to learn Python for Data Science.\",\n    \"Can you review my resume?\",\n    \"I have a big interview coming up on Monday.\",\n    \"Hi, I need career help.\"\n]\n\nprint(f\"{'USER INPUT':<45} | {'INTENT':<15} | {'REPLY'}\")\nprint(\"-\" * 110)\n\nfor msg in messages:\n    out = career_bot.ask(msg)\n    # Printing a truncated version of the reply to keep the table clean\n    preview_reply = out['reply'][:60].replace('\\n', ' ') + \"...\"\n    print(f\"{msg:<45} | {out['intent']:<15} | {preview_reply}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T18:28:04.767791Z","iopub.execute_input":"2025-11-20T18:28:04.768036Z","iopub.status.idle":"2025-11-20T18:28:10.151137Z","shell.execute_reply.started":"2025-11-20T18:28:04.768016Z","shell.execute_reply":"2025-11-20T18:28:10.150272Z"}},"outputs":[{"name":"stdout","text":"USER INPUT                                    | INTENT          | REPLY\n--------------------------------------------------------------------------------------------------------------\nI need to learn Python for Data Science.      | learning_path   | Okay, great! Learning Python for Data Science is a fantastic...\nCan you review my resume?                     | resume_review   | Okay, I can definitely help with that! To give you the best ...\nI have a big interview coming up on Monday.   | interview_prep  | That's great you have an interview coming up! Let's get you ...\nHi, I need career help.                       | general_help    | Hi! I'm happy to help you navigate your career path. To give...\n","output_type":"stream"}],"execution_count":24}]}